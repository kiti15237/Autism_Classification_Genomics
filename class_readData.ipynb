{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load input feature dataset for Agre\n",
    "Agre_asd = pd.read_csv(\"data/v34_lof_asd_af0.50.txt\", index_col=0).transpose()\n",
    "Agre_ctrl = pd.read_csv(\"data/v34_lof_typical_af0.50.txt\", index_col=0).transpose()\n",
    "\n",
    "print(\"Cases: \", Agre_asd.shape[0])\n",
    "print(\"Controls: \", Agre_ctrl.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load input feature dataset for SSC\n",
    "SSC_asd = pd.read_csv(\"data/SSC_lof_asd_af0.50.txt\", index_col=0).transpose()\n",
    "SSC_ctrl = pd.read_csv(\"data/SSC_lof_typical_af0.50.txt\", index_col=0).transpose()\n",
    "\n",
    "print (\"Cases: \", SSC_asd.shape[0])\n",
    "print (\"Controls: \", SSC_ctrl.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge SSC and Agre data\n",
    "X_asd = pd.concat([SSC_asd, Agre_asd], axis = 0).fillna(0)\n",
    "X_ctrl = pd.concat([SSC_ctrl, Agre_ctrl], axis = 0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X_asd, X_ctrl], axis=0)\n",
    "print (\"Total cases: \", X_asd.shape[0])\n",
    "print (\"Total controls: \", X_ctrl.shape[0])\n",
    "print (\"Features (ie. genes): \", X.shape[1])\n",
    "print (\"Missing Values: \", int(X.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Data (ASD/non-ASD diagnosis)\n",
    "\n",
    "We have a file that Kelley has made with inferred Autism/Control diagnosis for the individuals in the iHart study.  We will try and predict diagnosis 0 = Control, 1 = Austism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/all_samples_filtered_labels.csv\", usecols = ['identifier','diagnosis'], index_col=0)\n",
    "# shift y to a 0/1 representation for Control/ASD\n",
    "y[\"diagnosis\"] = np.where(y['diagnosis'] == 'Autism', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get lists of individuals in X and Y\n",
    "m_x = X.index.values.tolist()\n",
    "m_x_asd = X_asd.index.tolist()\n",
    "m_x_ctrl = X_ctrl.index.tolist()\n",
    "m_y = y.index.values.tolist()\n",
    "\n",
    "# check subject overlap between X and Y\n",
    "print (\"%d subjects in X are not in y.  Of these, %d are cases and %d are controls.\" % (len(set(m_x) - set(m_y)), len(set(m_x_asd) - set(m_y)), len(set(m_x_ctrl) - set(m_y))))\n",
    "\n",
    "# make a list of Subject IDs with overlap\n",
    "subjects = list(set(m_x) & set(m_y))\n",
    "print (\"This leaves %d subjects: %d cases and %d controls.\" % (len(subjects), len(set(m_x_asd) & set(m_y)), len(set(m_x_ctrl)&set(m_y))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The set of \"cases\" and \"controls\" appear to be differently defined between the iHart Phenotype labels (i.e. our `y` labels) and the CGT matrix labels (i.e. our `X` features). \n",
    "\n",
    "You can notice that the majority of controls don't appear in our phenotype information dataset. This is because ADOS\\ADI-R was not administered to many controls from SSC and Agre. Since we're interested in classifying ASD/non-ASD, for our purposes it is not necessary to exclude these individuals because we do not necessarily need any phenotype information outside of diagnosis. Rather, we can infer that all individuals in a 'control' CGT matrix without ADOS/ADI-R information have a non-ASD diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_add = list(set(m_x_ctrl) - set(m_y))\n",
    "y_ctrl = pd.DataFrame(np.zeros(len(to_add),), columns = ['diagnosis'],index = to_add)\n",
    "y = pd.concat([y, y_ctrl], axis = 0)\n",
    "subjects = subjects + to_add\n",
    "print (len(subjects))\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redefine X and Y to contain only the subjects we want\n",
    "X = X.ix[subjects]\n",
    "y = y.ix[subjects]\n",
    "\n",
    "# check we have the same subject IDs in the same order for X and Y\n",
    "print( y.index.values.tolist() == X.index.values.tolist())\n",
    "y = y.ix[:,0]\n",
    "print (y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that's probably going to be an issue for this experiment is that there are very few controls for whom we have both genetic and ADOS/ADI-R information.  This is going to mean that a random classifier performs with fairly high accuracy, just because classifying most or all individuals as autistic is a effective strategy when we have so few negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Splitting\n",
    "\n",
    "Since we have ~1,600 examples, I'm going to hold out 20% of the data as a test set and then do 5 fold cross validation using built-in sklearn methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(143)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Note, we could do this splitting by family id using model_selection.GroupKFold\n",
    "#>>> group_kfold = GroupKFold(n_splits=2)\n",
    "#>>> group_kfold.get_n_splits(X, y, groups)\n",
    "#groups = pair id\n",
    "#BUT rocky's class should work (not on my local machine) well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
